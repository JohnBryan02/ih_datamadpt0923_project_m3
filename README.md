# Data Project README file

### :raising_hand: **Nombre** 
<<<<<<< HEAD
Mis primeros spaguettis

### :baby: **Estado**
Ironhack Data Analytics Primer Proyecto Beta

### :running: **Utilidad**
Este proyecto consiste en obtener como resultado el bicimad o bicipark mÃ¡s cercano en funciÃ³n de los centros culturales de Madrid. Aparte de esta informaciÃ³n tambiÃ©n se aÃ±ade la disponibilidad de las bicis actuales que hay en la estaciÃ³n cercana y un enlace directo a google maps para que el usuario pueda dirigirse a la estaciÃ³n.

### :computer: **Herramientas**
Python, visual studio, jupyter.


### :wrench: **ConfiguraciÃ³n**
Librerias que debes tener para que este programa funcione.
- import pandas as pd
- import requests
- import bs4
- from shapely.geometry import Point
- import geopandas as gpd
- import argparse
- from fuzzywuzzy import fuzz
- from fuzzywuzzy import process
- import os
- from dotenv import load_dotenv
- import argparse
- import papermill

### :see_no_evil: **Uso**
Al ejecutar el programa en una terminal se solicitarÃ¡n dos o tres inputs().

- Primera opciÃ³n(dos inputs): "Todos" + "bicimad o bicipark" esto generarÃ¡ un dataframe completo con centros culturales y bicimads o biciparks. 
Esto generara un dataframe completo con centros culturales y bicimads o biciparks
- Segunda opciÃ³n(tres inputs): "Centro cultural" + "bicimad o bicipark" + "Si o No" esto ultimo nos dara un enlace a google maps si lo deseamos.
Esta opciÃ³n generarÃ¡ un data frame de una Ãºnica fila con el centro cultural seleccionado y el transporte elegido. AdemÃ¡s, tendrÃ¡s la opciÃ³n de obtener un enlace a Google Maps.

Problema: tiempo de ejecuciÃ³n demasiado largo.

### :file_folder: **Estructura de carpetas**
```
â””â”€â”€ ih_datamadpt0923_project_m1
=======
ML Diamonds Price
### :baby: **Estado**
Ironhack Data Analytics Tercer Proyecto Beta

### :running: **Utilidad**
En este proyecto empleamos ML para predecir el precio del diamante en funciÃ³n de diferentes features.
### :computer: **Herramientas**
Python, visual studio, jupyter, Dbeaver(SQL), Terminal


### :wrench: **ConfiguraciÃ³n**
Librerias que debes tener para que este programa funcione. (Se recomienda tener un entorno Ãºnico con estas librerias).
lazypredict
sklearn
pandas
seaborn
numpy
matplotlib
Se ejecuta atravÃ©s de jupyter notebook en el archivo soluciÃ³n_final.
Usamos el archivo diamond_test.csv para probar nuestro entrenamiento de datos.


### :see_no_evil: **Pasos**
Abrimos el documento diamonds_train.db en dbeaver y hacemos un join de todas las tablas que tenemos para ver que podemos usar. Generamos un CSV y lo cargamos en jupyter notebook.

Exploramos nuestros datos y eliminamos lo que no necesitemos. En mi caso he usado la matriz de correlaciÃ³n con seaborn para ver que columnas no nos estaban aportando valor.

Una vez que tenemos los datos limpios he usado lazy predict para ver que modelos nos dan mejores mÃ©tricas.
- Modelo usado finalmente: XGBRegressor
- Modelos Testeados: 
            LGBMRegressor (Mejor scoring en lazy predict pero a la hora de entrenar se quedaba detrÃ¡s)
            LinearRegression, 
            RandomForestRegressor,
            HistGradientBoostingRegressor   
            GradientBoostingRegressor   
            XGBRegressor   
            RandomForestRegressor   
            ExtraTreesRegressor   
            MLPRegressor   
            BaggingRegressor   
            KNeighborsRegressorOrthogonalMatchingPursuitCV
            LassoLars
            Lasso 
Comparamos nuestros datos test frente a los datos entrenados y realizamos un predict.

Guardamos el csv, abrimos visual estudio y probamos a subirlo a kaggle ðŸ¤ž


### :books: **Learnings**
Features que he metido para mejorar el training
Librerias que he probado nuevas
### :x: **Error Principal**
Quedarse dormido. Con todos estos test y diferentes modelos he podido comprender el funcionamiento basico del machine learning
y los diferentes pasos que se deben ir siguiendo. El orden es un factor importante en este proyecto.

### :file_folder: **Estructura de carpetas**
```
â””â”€â”€ ih_datamadpt0923_project_m3
>>>>>>> 0dcc12a3b6d6f79b035635e846ee6a07c1941d14
    â”œâ”€â”€ .ipynb_checkpoints
    â”œâ”€â”€ _wip_
    â””â”€â”€ data
    â”‚   â”œâ”€â”€ final_filas_libm_live.csv
    â”‚   â””â”€â”€ final_filas_libp_live.csv
    â”œâ”€â”€ modules
    â”‚   â”œâ”€â”€ funciones.py
    â”‚   â””â”€â”€ geocalculations.py     
    â”œâ”€â”€ notebooks
    â”‚   â””â”€â”€ importing_exporting_dfs.ipynb
    â”œâ”€â”€ LICENSE
    â”œâ”€â”€ .env
    â”œâ”€â”€ README.md
    â””â”€â”€ main.py
```


### :shit: **ToDo**
<<<<<<< HEAD
Mejora del tiempo de ejecuciÃ³n.
=======
- Mejorar el guardado a CSV para evitar tener que abrir VS y modificar manualmente.
- Reestructurar el cÃ³digo para evitar tener que ordenar las columnas nuevamente.
- Matriz de correlaciÃ³n intentar llevar antes de realizar el drop para que no sea tan complicado usarlo.
- Limpiar imports
- Limpiar features
>>>>>>> 0dcc12a3b6d6f79b035635e846ee6a07c1941d14

### :love_letter: **Contact info**
John Bryan xxxxxxxx@gmail.com

---
